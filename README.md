# ğŸš€ SLMGEN - Small Language Model Generator

[![License: MIT](https://img.shields.io/badge/License-MIT-teal.svg)](https://opensource.org/licenses/MIT)
[![CI](https://github.com/eshanized/slmgen/actions/workflows/ci.yml/badge.svg)](https://github.com/eshanized/slmgen/actions/workflows/ci.yml)

<div align="center">

![SLMGEN Landing Page](docs/images/screenshot.png)

**Fine-tune SLMs. 2x faster. For free.**

[Live Demo](https://slmgen.vercel.app) Â· [API Docs](docs/API.md) Â· [User Guide](docs/USER_GUIDE.md)

</div>

---

## âœ¨ What is SLMGEN?

SLMGEN is a production-ready web application that automates SLM fine-tuning. Upload your JSONL dataset and receive ready-to-run Google Colab notebooks with Unsloth + LoRA optimization.

**Your Data â†’ Best Model â†’ Matched.** One notebook. Zero setup. Ready to train.

---

## ğŸ¯ Core Features

| Feature | Description |
|---------|-------------|
| ğŸ“¤ **Smart Upload** | Drag-and-drop JSONL with instant validation (min 50 examples) |
| ğŸ“Š **Quality Scoring** | Duplicate detection, consistency checks, 0-100% quality score |
| ğŸ§  **11 Model Support** | Phi-4, Llama 3.2, Gemma 2, Qwen 2.5, Mistral 7B + more |
| ğŸ¯ **100-Point Matching** | Task fit (50pts) + Deploy target (30pts) + Data traits (20pts) |
| ğŸ““ **Self-Contained Notebooks** | Dataset embedded as base64 - no file uploads needed |
| â˜ï¸ **6 Deploy Targets** | Cloud, Server, Desktop, Edge, Mobile, Browser |

---

## ğŸ§  Advanced Intelligence Features

### Dataset Intelligence Layer
- **Personality Detection** - Infers tone, verbosity, technicality, strictness
- **Hallucination Risk** - Scores likelihood of model fabrication (0-1)
- **Confidence Score** - Measures training reliability via coverage/diversity

### Prompt & Behavior Engine
- **Behavior Composer** - Generate system prompts from trait sliders
- **Prompt Linter** - Detects contradictions, redundancy, ambiguity
- **Prompt Diff** - Semantic comparison between prompts

### Model Transparency
- **"Why This Model?"** - Strength/weakness deep dive per model
- **Failure Previews** - Synthetic failure cases before training
- **Model Card Generator** - Auto-generated deployment README

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Backend** | Python 3.11, FastAPI, Pydantic v2 |
| **Frontend** | Next.js 16, TypeScript, React 19 |
| **Auth** | Supabase (OAuth + Email) |
| **Training** | Unsloth + LoRA on Google Colab (Free T4) |
| **Deployment** | Vercel (Frontend) + Render (Backend) |

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- Supabase project

### Backend

```bash
cd libslmgen
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env  # Configure Supabase keys
uvicorn app.main:app --reload --port 8000
```

### Frontend

```bash
cd slmgenui
npm install
cp .env.example .env.local  # Configure API URL + Supabase
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) ğŸ‰

---

## ğŸ“ Project Structure

```
slmgen/
â”œâ”€â”€ libslmgen/                  # Python Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI app
â”‚   â”‚   â”œâ”€â”€ routers/            # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py       # Dataset upload
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze.py      # Dataset analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ recommend.py    # Model recommendation
â”‚   â”‚   â”‚   â”œâ”€â”€ generate.py     # Notebook generation
â”‚   â”‚   â”‚   â”œâ”€â”€ advanced.py     # Intelligence features
â”‚   â”‚   â”‚   â””â”€â”€ jobs.py         # Job history
â”‚   â”‚   â””â”€â”€ session.py          # Thread-safe sessions
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ ingest.py           # JSONL parsing
â”‚       â”œâ”€â”€ quality.py          # Quality scoring
â”‚       â”œâ”€â”€ analyzer.py         # Dataset analysis
â”‚       â”œâ”€â”€ recommender.py      # 100-point scoring engine
â”‚       â”œâ”€â”€ notebook.py         # Jupyter generator
â”‚       â”œâ”€â”€ personality.py      # Personality detection
â”‚       â”œâ”€â”€ risk.py             # Hallucination risk
â”‚       â”œâ”€â”€ confidence.py       # Training confidence
â”‚       â”œâ”€â”€ behavior.py         # Behavior composer
â”‚       â”œâ”€â”€ prompt_linter.py    # Prompt linting
â”‚       â””â”€â”€ model_card.py       # README generator
â”œâ”€â”€ slmgenui/                   # Next.js Frontend
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/                # Pages (dashboard, login, signup)
â”‚       â”œâ”€â”€ components/         # UI components
â”‚       â”œâ”€â”€ lib/                # API client & types
â”‚       â””â”€â”€ hooks/              # React hooks (with persistence)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md                  # API reference
â”‚   â”œâ”€â”€ USER_GUIDE.md           # User guide
â”‚   â””â”€â”€ DEPLOY.md               # Deployment guide
â””â”€â”€ supabase/
    â””â”€â”€ schema.sql              # Database schema
```

---

## ğŸ“Š Supported Models

| Model | Size | Context | Best For | Gated |
|-------|------|---------|----------|-------|
| **Phi-4 Mini** | 3.8B | 16K | Classification, Extraction | âŒ |
| **Llama 3.2** | 1B/3B | 8K | Q&A, Conversations | âœ… |
| **Gemma 2** | 2B | 8K | Edge, Mobile | âœ… |
| **Qwen 2.5** | 0.5B-3B | 32K | Multilingual, JSON | âŒ |
| **Mistral 7B** | 7B | 32K | Generation, Creative | âŒ |
| **TinyLlama** | 1.1B | 2K | Ultra-lightweight | âŒ |
| **SmolLM2** | 135M-1.7B | 8K | Small devices | âŒ |

---

## ğŸ“¦ Dataset Format

Each line in your JSONL file should be a conversation:

```json
{"messages": [{"role": "user", "content": "Hello!"}, {"role": "assistant", "content": "Hi there!"}]}
{"messages": [{"role": "system", "content": "You are helpful."}, {"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}
```

**Requirements:**
- âœ… Minimum 50 examples
- âœ… At least one user and one assistant message
- âœ… UTF-8 encoding
- âœ… Valid JSON per line

---

## ğŸŒ Deployment

### Vercel (Frontend)
```bash
npx vercel --prod
```

### Render (Backend)
Uses `render.yaml` blueprint for auto-deployment.

See [DEPLOY.md](docs/DEPLOY.md) for full instructions.

---

## âš™ï¸ Environment Variables

```bash
# Backend (.env)
ALLOWED_ORIGINS=https://slmgen.vercel.app,http://localhost:3000
UPLOAD_DIR=/tmp/uploads
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_key
JWT_SECRET=your_jwt_secret

# Frontend (.env.local)
NEXT_PUBLIC_API_URL=https://slmgen-api.onrender.com
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key
```

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE)

---

## ğŸ‘¤ Author

**Eshan Roy**
- ğŸ“§ eshanized@proton.me
- ğŸ™ [@eshanized](https://github.com/eshanized)

---

<div align="center">

**â­ Star this repo if SLMGEN helped you fine-tune faster!**

</div>
