# ğŸš€ SLMGEN - Small Language Model Generator

**Fine-tune SLMs. 2x faster. For free.**

SLMGEN is a web application that automates SLM fine-tuning. Upload your JSONL data and receive ready-to-run Google Colab notebooks.

## âœ¨ Features

- ğŸ“¤ **Upload** - Drag-and-drop JSONL datasets with instant validation
- ğŸ“Š **Analyze** - Automatic quality scoring and characteristic detection
- ğŸ¯ **Recommend** - AI-powered model selection based on your data
- ğŸš€ **Generate** - Self-contained Colab notebooks with embedded datasets

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Backend** | Python 3.11+, FastAPI, Pydantic |
| **Frontend** | Next.js 14, TypeScript, Tailwind CSS |
| **Training** | Unsloth + LoRA on Google Colab (Free T4) |

## ğŸš€ Quick Start

### Backend

```bash
cd libslmgen
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
```

### Frontend

```bash
cd slmgenui
npm install
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to start fine-tuning!

## ğŸ“ Project Structure

```
slmgen/
â”œâ”€â”€ libslmgen/              # Python Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI app
â”‚   â”‚   â”œâ”€â”€ config.py       # Settings
â”‚   â”‚   â”œâ”€â”€ models.py       # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ session.py      # Session manager
â”‚   â”‚   â””â”€â”€ routers/        # API endpoints
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ ingest.py       # JSONL parsing
â”‚       â”œâ”€â”€ quality.py      # Quality scoring
â”‚       â”œâ”€â”€ analyzer.py     # Dataset analysis
â”‚       â”œâ”€â”€ recommender.py  # Model selection
â”‚       â””â”€â”€ notebook.py     # Notebook generator
â”œâ”€â”€ slmgenui/               # Next.js Frontend
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/            # Pages
â”‚       â”œâ”€â”€ components/     # UI components
â”‚       â”œâ”€â”€ lib/            # API client & types
â”‚       â””â”€â”€ hooks/          # React hooks
â””â”€â”€ LICENSE
```

## ğŸ“Š Supported Models

| Model | Size | Best For |
|-------|------|----------|
| **Phi-4 Mini** | 3.8B | Classification, Extraction |
| **Llama 3.2** | 3B | Q&A, Conversations |
| **Gemma 2** | 2B | Edge, Mobile |
| **Qwen 2.5** | 3B | Multilingual, JSON |
| **Mistral 7B** | 7B | Generation |

## ğŸ“¦ Dataset Format

Each line in your JSONL file should be a conversation:

```json
{"messages": [{"role": "user", "content": "Hello!"}, {"role": "assistant", "content": "Hi there!"}]}
{"messages": [{"role": "system", "content": "You are helpful."}, {"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}
```

**Requirements:**
- Minimum 50 examples
- At least one user and one assistant message per conversation
- UTF-8 encoding

## âš™ï¸ Environment Variables

```bash
# Backend (.env)
ALLOWED_ORIGINS=http://localhost:3000
UPLOAD_DIR=./uploads
GITHUB_TOKEN=           # Optional, for Colab URLs

# Frontend (.env.local)
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE)

## ğŸ‘¤ Author

**Eshan Roy**
- Email: eshanized@proton.me
- GitHub: [@eshanized](https://github.com/eshanized)
